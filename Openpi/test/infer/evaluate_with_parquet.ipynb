{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a58fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:正在从 /home/adminroot/lxx/dataset/uav_flow_lerobot_format/fixed_command/pass/test/uav_flow/data/chunk-000/episode_000441.parquet 加载并处理 Parquet 数据...\n",
      "ERROR:root:未能从 Parquet 文件加载数据。正在中止。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无法加载 Parquet 文件 /home/adminroot/lxx/dataset/uav_flow_lerobot_format/fixed_command/pass/test/uav_flow/data/chunk-000/episode_000441.parquet: [Errno 2] No such file or directory: '/home/adminroot/lxx/dataset/uav_flow_lerobot_format/fixed_command/pass/test/uav_flow/data/chunk-000/episode_000441.parquet'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from openpi_client import websocket_client_policy as _websocket_client_policy\n",
    "\n",
    "sys.path.append('/home/adminroot/lxx/openpi/code/openpi/test/parquet_2_json/uav_flow')\n",
    "from parquet_2_json import process_parquet_episode\n",
    "# 添加路径以导入视频生成脚本\n",
    "sys.path.append('/home/adminroot/lxx/openpi/code/openpi/test/infer/trajectory_video/py')\n",
    "from trajectory_video_new import generate_video_from_trajectory\n",
    "\n",
    "def get_prompt_from_task_index(tasks_jsonl_path, task_index):\n",
    "    \"\"\"\n",
    "    从 tasks.jsonl 文件中根据 task_index 查找并返回对应的 prompt。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(tasks_jsonl_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                if data.get('task_index') == task_index:\n",
    "                    return data.get('task')\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"tasks.jsonl 文件未找到: {tasks_jsonl_path}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(f\"解析 tasks.jsonl 文件时出错: {tasks_jsonl_path}\")\n",
    "        return None\n",
    "    \n",
    "    logging.warning(f\"在 {tasks_jsonl_path} 中未找到 task_index {task_index} 对应的任务。\")\n",
    "    return None\n",
    "\n",
    "def calculate_trajectory_deviation(traj1, traj2):\n",
    "    \"\"\"\n",
    "    计算两条轨迹的位置和姿态偏差。\n",
    "    轨迹应为 (N, 6) 的形状，其中 N 是点数，6是 (x, y, z, roll, pitch, yaw)。\n",
    "    \"\"\"\n",
    "    pos1, rot1 = traj1[:, :3], traj1[:, 3:]\n",
    "    pos2, rot2 = traj2[:, :3], traj2[:, 3:]\n",
    "\n",
    "    positional_errors = np.linalg.norm(pos1 - pos2, axis=1)\n",
    "    positional_mae = np.mean(positional_errors)\n",
    "\n",
    "    rotational_errors = np.abs(rot1 - rot2)\n",
    "    rotational_mae = np.mean(rotational_errors)\n",
    "\n",
    "    return positional_mae, rotational_mae, positional_errors\n",
    "\n",
    "\n",
    "def visualize_trajectories_3d(traj1, traj2):\n",
    "    \"\"\"\n",
    "    使用 matplotlib 可视化两条3D轨迹。\n",
    "    \"\"\"\n",
    "    pos1 = traj1[:, :3]\n",
    "    pos2 = traj2[:, :3]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # 交换X和Y轴以匹配俯视图\n",
    "    ax.plot(pos1[:, 1], pos1[:, 0], pos1[:, 2], 'o-', label='Original Trajectory', color='blue')\n",
    "    ax.plot(pos2[:, 1], pos2[:, 0], pos2[:, 2], 'o-', label='Inferred Trajectory', color='red')\n",
    "\n",
    "    for i in range(len(pos1)):\n",
    "        ax.plot([pos1[i, 1], pos2[i, 1]], [pos1[i, 0], pos2[i, 0]], [pos1[i, 2], pos2[i, 2]],\n",
    "                '--', color='gray', linewidth=0.8)\n",
    "\n",
    "    ax.set_xlabel('Y')\n",
    "    ax.set_ylabel('X')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Trajectory Comparison')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_trajectories_2d_topdown(traj1, traj2):\n",
    "    \"\"\"\n",
    "    使用 matplotlib 可视化两条轨迹的俯视图。\n",
    "    横轴为Y (左/右), 纵轴为X (前/后)\n",
    "    \"\"\"\n",
    "    pos1 = traj1[:, :2]  # 只取 X, Y 坐标\n",
    "    pos2 = traj2[:, :2]  # 只取 X, Y 坐标\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # 交换X和Y轴进行绘图\n",
    "    ax.plot(pos1[:, 1], pos1[:, 0], 'o-', label='Original Trajectory', color='blue')\n",
    "    ax.plot(pos2[:, 1], pos2[:, 0], 'o-', label='Inferred Trajectory', color='red')\n",
    "\n",
    "    for i in range(len(pos1)):\n",
    "        ax.plot([pos1[i, 1], pos2[i, 1]], [pos1[i, 0], pos2[i, 0]],\n",
    "                '--', color='gray', linewidth=0.8)\n",
    "\n",
    "    ax.set_xlabel('Y (m, Left/Right)')\n",
    "    ax.set_ylabel('X (m, Forward/Backward)')\n",
    "    ax.set_title('Trajectory Comparison (Top-down View)')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    HOST = \"0.0.0.0\"\n",
    "    PORT = 8000\n",
    "    # 将此路径更改为指向 Parquet 文件\n",
    "    # EPISODE_DATA_PATH = \"/home/adminroot/lxx/dataset/uav_flow_lerobot_format/fixed_command/pass/train_without_first_10/uav_flow/data/chunk-000/episode_000022.parquet\"\n",
    "    # EPISODE_DATA_PATH = \"/home/adminroot/lxx/dataset/uav_flow_lerobot_format/train/uav_flow/data/chunk-000/episode_000020.parquet\"\n",
    "    # 这条数据感觉有问题\n",
    "    # EPISODE_DATA_PATH = \"/home/adminroot/lxx/dataset/uav_flow_lerobot_format/fixed_command/train0621/uav_flow/data/chunk-000/episode_000102.parquet\"\n",
    "    EPISODE_DATA_PATH = \"/home/adminroot/lxx/dataset/uav_flow_lerobot_format/fixed_command/pass/test/uav_flow/data/chunk-004/episode_000441.parquet\"\n",
    "    REPLAN_STEPS = 10  # 每次推理后取前10个动作\n",
    "    IGNORE_FIRST_10 = False  # 开关：True则忽略前10条数据，False则保持原样\n",
    "\n",
    "    logging.info(f\"正在从 {EPISODE_DATA_PATH} 加载并处理 Parquet 数据...\")\n",
    "    \n",
    "    # 定义提取出的图像的存放位置。评估脚本需要这些位于磁盘上的图像。\n",
    "    output_dir_for_images = \"/home/adminroot/lxx/openpi/code/openpi/test/infer/infer_output\"\n",
    "    \n",
    "    # 调用函数来处理 Parquet 文件。\n",
    "    # 它会将图像保存到 `output_dir_for_images` 并返回所需的数据结构。\n",
    "    episode_data = process_parquet_episode(EPISODE_DATA_PATH, output_dir_for_images, save_json=True)\n",
    "\n",
    "    if IGNORE_FIRST_10:\n",
    "        if len(episode_data) > 10:\n",
    "            logging.info(\"开关为True，正在忽略原始数据中的前10条数据...\")\n",
    "            episode_data = episode_data[10:]\n",
    "        else:\n",
    "            logging.warning(f\"数据总数不足10条 (只有 {len(episode_data)} 条)，无法忽略。将使用所有数据。\")\n",
    "\n",
    "    if not episode_data:\n",
    "        logging.error(\"未能从 Parquet 文件加载数据。正在中止。\")\n",
    "        return\n",
    "\n",
    "    # 1. 从 episode 数据中获取 task_index\n",
    "    if 'task_index' not in episode_data[0] or episode_data[0]['task_index'] is None:\n",
    "        logging.error(\"在 episode 数据的第一帧中未找到 'task_index'。\")\n",
    "        return\n",
    "    task_index = episode_data[0]['task_index']\n",
    "\n",
    "    # 2. 构造 tasks.jsonl 的路径\n",
    "    try:\n",
    "        # 假设路径结构为 .../test/uav_flow/data/chunk-xxx/episode_xxxxx.parquet\n",
    "        # 我们需要 .../test/uav_flow/meta/tasks.jsonl\n",
    "        base_path = os.path.dirname(os.path.dirname(os.path.dirname(EPISODE_DATA_PATH)))\n",
    "        tasks_jsonl_path = os.path.join(base_path, 'meta', 'tasks.jsonl')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"无法从 EPISODE_DATA_PATH 推断 'meta' 目录路径: {EPISODE_DATA_PATH}. Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # 3. 获取 PROMPT\n",
    "    PROMPT = get_prompt_from_task_index(tasks_jsonl_path, task_index)\n",
    "    if PROMPT is None:\n",
    "        logging.error(\"无法获取 PROMPT。正在中止。\")\n",
    "        return\n",
    "    \n",
    "    logging.info(f\"成功获取任务提示: '{PROMPT}'\")\n",
    "\n",
    "    MAX_STEPS = len(episode_data)  # 将总步数设置为数据中的对象数量\n",
    "\n",
    "    # 构造原始轨迹\n",
    "    # 原始轨迹由第0帧的状态和之后每一帧的动作组成\n",
    "    # 注意：在数据集中，frame_i 的 state 等于 frame_i-1 的 actions\n",
    "    # 因此，真实的轨迹点是所有 object 的 state 加上最后一个 object 的 actions\n",
    "    original_trajectory_states = [np.array(d['state']) for d in episode_data]\n",
    "    original_trajectory_states.append(np.array(episode_data[-1]['actions']))\n",
    "    original_trajectory = np.array(original_trajectory_states)\n",
    "\n",
    "\n",
    "    logging.info(f\"正在连接到服务器 ws://{HOST}:{PORT}\")\n",
    "    client = _websocket_client_policy.WebsocketClientPolicy(HOST, PORT)\n",
    "\n",
    "    all_inferred_actions = []\n",
    "    \n",
    "    # 首次推理\n",
    "    # 使用第一个 object 的数据进行初始化\n",
    "    current_state = np.array(episode_data[0]['state'])\n",
    "    image_path = episode_data[0]['image_path']\n",
    "    \n",
    "    logging.info(\"开始循环推理...\")\n",
    "    for i in range(0, MAX_STEPS, REPLAN_STEPS):\n",
    "        logging.info(f\"正在执行推理步: {i+1}-{i+REPLAN_STEPS}\")\n",
    "        \n",
    "        # 构造输入 example\n",
    "        # image 固定不变, wrist_image 和 state 变化\n",
    "        wrist_image_path = episode_data[i]['wrist_image_path']\n",
    "        \n",
    "        element = {\n",
    "            \"observation/image\": imageio.imread(image_path),\n",
    "            \"observation/wrist_image\": imageio.imread(wrist_image_path),\n",
    "            \"observation/state\": current_state,\n",
    "            \"prompt\": PROMPT\n",
    "        }\n",
    "\n",
    "        # 调用 server 进行推理\n",
    "        action_chunk = client.infer(element)[\"actions\"]\n",
    "        all_inferred_actions.extend(action_chunk)\n",
    "\n",
    "        # 更新下一次推理的状态\n",
    "        # 使用返回的动作序列的最后一个点的6D位姿作为下一次的起始状态\n",
    "        current_state = np.array(action_chunk[-1][:6])\n",
    "\n",
    "    logging.info(\"推理完成。\")\n",
    "\n",
    "    # 构造推理轨迹\n",
    "    # 推理出的轨迹是初始状态加上所有推理出的动作\n",
    "    inferred_trajectory_states = [np.array(episode_data[0]['state'])]\n",
    "    inferred_trajectory_states.extend([np.array(act[:6]) for act in all_inferred_actions])\n",
    "    inferred_trajectory = np.array(inferred_trajectory_states)\n",
    "    \n",
    "    # 确保两条轨迹长度一致以便比较\n",
    "    min_len = min(len(original_trajectory), len(inferred_trajectory))\n",
    "    original_trajectory = original_trajectory[:min_len]\n",
    "    inferred_trajectory = inferred_trajectory[:min_len]\n",
    "\n",
    "    # 计算偏差并输出结果\n",
    "    pos_mae, rot_mae, pos_errors = calculate_trajectory_deviation(original_trajectory, inferred_trajectory)\n",
    "\n",
    "    print(\"\\n--- 轨迹偏差分析 ---\")\n",
    "    print(f\"平均绝对位置误差 (Positional MAE): {pos_mae:.4f}\")\n",
    "    print(f\"平均绝对姿态误差 (Rotational MAE): {rot_mae:.4f}\")\n",
    "    print(\"\\n每个点的具体位置误差:\")\n",
    "    for i, err in enumerate(pos_errors):\n",
    "        print(f\"  点 {i}: {err:.4f}\")\n",
    "    print(\"------------------------\\n\")\n",
    "\n",
    "    # 可视化轨迹\n",
    "    logging.info(\"正在生成轨迹对比图...\")\n",
    "    visualize_trajectories_3d(original_trajectory, inferred_trajectory)\n",
    "    visualize_trajectories_2d_topdown(original_trajectory, inferred_trajectory)    \n",
    "\n",
    "    # 从EPISODE_DATA_PATH动态生成输出JSON文件名\n",
    "    episode_match = re.search(r'episode_(\\d+)\\.parquet$', EPISODE_DATA_PATH)\n",
    "    if episode_match:\n",
    "        episode_num = episode_match.group(1)\n",
    "        output_filename = f\"inferred_trajectory_{episode_num}.json\"\n",
    "    else:\n",
    "        output_filename = \"inferred_trajectory.json\" # Fallback\n",
    "\n",
    "    output_path = f\"/home/adminroot/lxx/openpi/code/openpi/test/infer/trajectory_video/{output_filename}\"\n",
    "    logging.info(f\"正在保存推理轨迹到 {output_path}...\")\n",
    "\n",
    "    # 准备用于JSON输出的数据列表\n",
    "    output_data = []\n",
    "    # 遍历原始的 episode 数据，以其长度为准\n",
    "    for i in range(len(episode_data)):\n",
    "        # 确保我们不会因为推理出的点数较少而出错\n",
    "        if i < len(inferred_trajectory):\n",
    "            # inferred_trajectory 的第一个点是初始状态，后续的点才是动作结果。\n",
    "            # 因此，第 i 个 object 对应的 action 是 inferred_trajectory 的第 i+1 个点。\n",
    "            # 我们需要检查 i+1 是否仍在 inferred_trajectory 的范围内。\n",
    "            if (i + 1) < len(inferred_trajectory):\n",
    "                action = inferred_trajectory[i+1].tolist()\n",
    "            else:\n",
    "                # 如果没有对应的推理动作（例如在最后一个点），则设为 None 或空列表\n",
    "                action = None\n",
    "        else:\n",
    "            action = None\n",
    "\n",
    "        output_data.append({\n",
    "            \"prompt\": PROMPT,\n",
    "            \"wrist_image_path\": episode_data[i]['wrist_image_path'],\n",
    "            \"state\": episode_data[i]['state'],\n",
    "            \"actions\": action\n",
    "        })\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "    \n",
    "    logging.info(f\"推理轨迹已保存到 {output_path}\")\n",
    "\n",
    "    # 自动调用脚本生成视频\n",
    "    logging.info(\"正在调用脚本生成轨迹视频...\")\n",
    "    try:\n",
    "        generate_video_from_trajectory(output_path)\n",
    "        logging.info(\"视频生成完毕。\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"生成视频时出错: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
