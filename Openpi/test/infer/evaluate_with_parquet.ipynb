{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a58fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:正在从 /data/vla/uav_flow_lerobot_3w_final/test/uav_flow/data/chunk-001/episode_000120.parquet 加载并处理 Parquet 数据...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理 Parquet 文件中的 52 行: /data/vla/uav_flow_lerobot_3w_final/test/uav_flow/data/chunk-001/episode_000120.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:成功获取任务提示: 'Go to the tree on the right side'\n",
      "INFO:root:正在连接到服务器 ws://0.0.0.0:8000\n",
      "INFO:root:Waiting for server at ws://0.0.0.0:8000...\n",
      "INFO:root:Still waiting for server...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "已将场景的采集数据保存至: /data/vla/VLA_Diff/Openpi/test/infer/infer_output/episode_data_120.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Still waiting for server...\n",
      "INFO:root:Still waiting for server...\n",
      "INFO:root:Still waiting for server...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/vla/VLA_Diff/Openpi/packages/openpi-client/src/openpi_client/websocket_client_policy.py:34\u001b[39m, in \u001b[36mWebsocketClientPolicy._wait_for_server\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     33\u001b[39m headers = {\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mApi-Key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._api_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_key \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m conn = \u001b[43mwebsockets\u001b[49m\u001b[43m.\u001b[49m\u001b[43msync\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m metadata = msgpack_numpy.unpackb(conn.recv())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/vla/VLA_Diff/Openpi/.venv/lib/python3.11/site-packages/websockets/sync/client.py:324\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(uri, sock, ssl, server_hostname, origin, extensions, subprotocols, compression, additional_headers, user_agent_header, proxy, proxy_ssl, proxy_server_hostname, open_timeout, ping_interval, ping_timeout, close_timeout, max_size, max_queue, logger, create_connection, **kwargs)\u001b[39m\n\u001b[32m    323\u001b[39m     kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m, deadline.timeout())\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     sock = \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mws_uri\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mws_uri\u001b[49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m sock.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/vipuser/miniconda3/envs/openpi/lib/python3.11/socket.py:863\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, all_errors)\u001b[39m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[32m--> \u001b[39m\u001b[32m863\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[32m0\u001b[39m]\n\u001b[32m    864\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ExceptionGroup(\u001b[33m\"\u001b[39m\u001b[33mcreate_connection failed\u001b[39m\u001b[33m\"\u001b[39m, exceptions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/vipuser/miniconda3/envs/openpi/lib/python3.11/socket.py:848\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, all_errors)\u001b[39m\n\u001b[32m    847\u001b[39m     sock.bind(source_address)\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 289\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    288\u001b[39m     logging.basicConfig(level=logging.INFO)\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 177\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    173\u001b[39m original_trajectory = np.array(original_trajectory_states)\n\u001b[32m    176\u001b[39m logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m正在连接到服务器 ws://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPORT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m client = \u001b[43m_websocket_client_policy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWebsocketClientPolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHOST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPORT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m all_inferred_actions = []\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# 首次推理\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# 使用第一个 object 的数据进行初始化\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/vla/VLA_Diff/Openpi/packages/openpi-client/src/openpi_client/websocket_client_policy.py:24\u001b[39m, in \u001b[36mWebsocketClientPolicy.__init__\u001b[39m\u001b[34m(self, host, port, api_key)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m._packer = msgpack_numpy.Packer()\n\u001b[32m     23\u001b[39m \u001b[38;5;28mself\u001b[39m._api_key = api_key\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28mself\u001b[39m._ws, \u001b[38;5;28mself\u001b[39m._server_metadata = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/vla/VLA_Diff/Openpi/packages/openpi-client/src/openpi_client/websocket_client_policy.py:41\u001b[39m, in \u001b[36mWebsocketClientPolicy._wait_for_server\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionRefusedError\u001b[39;00m:\n\u001b[32m     40\u001b[39m     logging.info(\u001b[33m\"\u001b[39m\u001b[33mStill waiting for server...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from openpi_client import websocket_client_policy as _websocket_client_policy\n",
    "\n",
    "sys.path.append('/data/vla/VLA_Diff/Openpi/test/parquet_2_json/uav_flow')\n",
    "from parquet_2_json import process_parquet_episode\n",
    "# 添加路径以导入视频生成脚本\n",
    "sys.path.append('/data/vla/VLA_Diff/Openpi/test/infer/trajectory_video/py')\n",
    "# from trajectory_video_new import generate_video_from_trajectory\n",
    "\n",
    "def get_prompt_from_task_index(tasks_jsonl_path, task_index):\n",
    "    \"\"\"\n",
    "    从 tasks.jsonl 文件中根据 task_index 查找并返回对应的 prompt。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(tasks_jsonl_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                if data.get('task_index') == task_index:\n",
    "                    return data.get('task')\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"tasks.jsonl 文件未找到: {tasks_jsonl_path}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(f\"解析 tasks.jsonl 文件时出错: {tasks_jsonl_path}\")\n",
    "        return None\n",
    "    \n",
    "    logging.warning(f\"在 {tasks_jsonl_path} 中未找到 task_index {task_index} 对应的任务。\")\n",
    "    return None\n",
    "\n",
    "def calculate_trajectory_deviation(traj1, traj2):\n",
    "    \"\"\"\n",
    "    计算两条轨迹的位置和姿态偏差。\n",
    "    轨迹应为 (N, 6) 的形状，其中 N 是点数，6是 (x, y, z, roll, pitch, yaw)。\n",
    "    \"\"\"\n",
    "    pos1, rot1 = traj1[:, :3], traj1[:, 3:]\n",
    "    pos2, rot2 = traj2[:, :3], traj2[:, 3:]\n",
    "\n",
    "    positional_errors = np.linalg.norm(pos1 - pos2, axis=1)\n",
    "    positional_mae = np.mean(positional_errors)\n",
    "\n",
    "    rotational_errors = np.abs(rot1 - rot2)\n",
    "    rotational_mae = np.mean(rotational_errors)\n",
    "\n",
    "    return positional_mae, rotational_mae, positional_errors\n",
    "\n",
    "\n",
    "def visualize_trajectories_3d(traj1, traj2):\n",
    "    \"\"\"\n",
    "    使用 matplotlib 可视化两条3D轨迹。\n",
    "    \"\"\"\n",
    "    pos1 = traj1[:, :3]\n",
    "    pos2 = traj2[:, :3]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # 交换X和Y轴以匹配俯视图\n",
    "    ax.plot(pos1[:, 1], pos1[:, 0], pos1[:, 2], 'o-', label='Original Trajectory', color='blue')\n",
    "    ax.plot(pos2[:, 1], pos2[:, 0], pos2[:, 2], 'o-', label='Inferred Trajectory', color='red')\n",
    "\n",
    "    for i in range(len(pos1)):\n",
    "        ax.plot([pos1[i, 1], pos2[i, 1]], [pos1[i, 0], pos2[i, 0]], [pos1[i, 2], pos2[i, 2]],\n",
    "                '--', color='gray', linewidth=0.8)\n",
    "\n",
    "    ax.set_xlabel('Y')\n",
    "    ax.set_ylabel('X')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Trajectory Comparison')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_trajectories_2d_topdown(traj1, traj2):\n",
    "    \"\"\"\n",
    "    使用 matplotlib 可视化两条轨迹的俯视图。\n",
    "    横轴为Y (左/右), 纵轴为X (前/后)\n",
    "    \"\"\"\n",
    "    pos1 = traj1[:, :2]  # 只取 X, Y 坐标\n",
    "    pos2 = traj2[:, :2]  # 只取 X, Y 坐标\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # 交换X和Y轴进行绘图\n",
    "    ax.plot(pos1[:, 1], pos1[:, 0], 'o-', label='Original Trajectory', color='blue')\n",
    "    ax.plot(pos2[:, 1], pos2[:, 0], 'o-', label='Inferred Trajectory', color='red')\n",
    "\n",
    "    for i in range(len(pos1)):\n",
    "        ax.plot([pos1[i, 1], pos2[i, 1]], [pos1[i, 0], pos2[i, 0]],\n",
    "                '--', color='gray', linewidth=0.8)\n",
    "\n",
    "    ax.set_xlabel('Y (m, Left/Right)')\n",
    "    ax.set_ylabel('X (m, Forward/Backward)')\n",
    "    ax.set_title('Trajectory Comparison (Top-down View)')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    HOST = \"0.0.0.0\"\n",
    "    PORT = 8000\n",
    "    # 将此路径更改为指向 Parquet 文件\n",
    "    # EPISODE_DATA_PATH = \"/home/adminroot/lxx/dataset/uav_flow_lerobot_format/fixed_command/pass/train_without_first_10/uav_flow/data/chunk-000/episode_000022.parquet\"\n",
    "    # EPISODE_DATA_PATH = \"/home/adminroot/lxx/dataset/uav_flow_lerobot_format/train/uav_flow/data/chunk-000/episode_000020.parquet\"\n",
    "    # 这条数据感觉有问题\n",
    "    # EPISODE_DATA_PATH = \"/home/adminroot/lxx/dataset/uav_flow_lerobot_format/fixed_command/train0621/uav_flow/data/chunk-000/episode_000102.parquet\"\n",
    "    # EPISODE_DATA_PATH = \"/data/vla/uav_flow_lerobot_3w_final/test/uav_flow/data/chunk-008/episode_000800.parquet\"\n",
    "    EPISODE_DATA_PATH = \"/data/vla/uav_flow_lerobot_3w_final/test/uav_flow/data/chunk-001/episode_000120.parquet\"\n",
    "    REPLAN_STEPS = 10  # 每次推理后取前10个动作\n",
    "    IGNORE_FIRST_10 = False  # 开关：True则忽略前10条数据，False则保持原样\n",
    "\n",
    "    logging.info(f\"正在从 {EPISODE_DATA_PATH} 加载并处理 Parquet 数据...\")\n",
    "    \n",
    "    # 定义提取出的图像的存放位置。评估脚本需要这些位于磁盘上的图像。\n",
    "    output_dir_for_images = \"/data/vla/VLA_Diff/Openpi/test/infer/infer_output\"\n",
    "    \n",
    "    # 调用函数来处理 Parquet 文件。\n",
    "    # 它会将图像保存到 `output_dir_for_images` 并返回所需的数据结构。\n",
    "    episode_data = process_parquet_episode(EPISODE_DATA_PATH, output_dir_for_images, save_json=True)\n",
    "\n",
    "    if IGNORE_FIRST_10:\n",
    "        if len(episode_data) > 10:\n",
    "            logging.info(\"开关为True，正在忽略原始数据中的前10条数据...\")\n",
    "            episode_data = episode_data[10:]\n",
    "        else:\n",
    "            logging.warning(f\"数据总数不足10条 (只有 {len(episode_data)} 条)，无法忽略。将使用所有数据。\")\n",
    "\n",
    "    if not episode_data:\n",
    "        logging.error(\"未能从 Parquet 文件加载数据。正在中止。\")\n",
    "        return\n",
    "\n",
    "    # 1. 从 episode 数据中获取 task_index\n",
    "    if 'task_index' not in episode_data[0] or episode_data[0]['task_index'] is None:\n",
    "        logging.error(\"在 episode 数据的第一帧中未找到 'task_index'。\")\n",
    "        return\n",
    "    task_index = episode_data[0]['task_index']\n",
    "\n",
    "    # 2. 构造 tasks.jsonl 的路径\n",
    "    try:\n",
    "        # 假设路径结构为 .../test/uav_flow/data/chunk-xxx/episode_xxxxx.parquet\n",
    "        # 我们需要 .../test/uav_flow/meta/tasks.jsonl\n",
    "        base_path = os.path.dirname(os.path.dirname(os.path.dirname(EPISODE_DATA_PATH)))\n",
    "        tasks_jsonl_path = os.path.join(base_path, 'meta', 'tasks.jsonl')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"无法从 EPISODE_DATA_PATH 推断 'meta' 目录路径: {EPISODE_DATA_PATH}. Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # 3. 获取 PROMPT\n",
    "    PROMPT = get_prompt_from_task_index(tasks_jsonl_path, task_index)\n",
    "    if PROMPT is None:\n",
    "        logging.error(\"无法获取 PROMPT。正在中止。\")\n",
    "        return\n",
    "    \n",
    "    logging.info(f\"成功获取任务提示: '{PROMPT}'\")\n",
    "\n",
    "    MAX_STEPS = len(episode_data)  # 将总步数设置为数据中的对象数量\n",
    "\n",
    "    # 构造原始轨迹\n",
    "    # 原始轨迹由第0帧的状态和之后每一帧的动作组成\n",
    "    # 注意：在数据集中，frame_i 的 state 等于 frame_i-1 的 actions\n",
    "    # 因此，真实的轨迹点是所有 object 的 state 加上最后一个 object 的 actions\n",
    "    original_trajectory_states = [np.array(d['state']) for d in episode_data]\n",
    "    original_trajectory_states.append(np.array(episode_data[-1]['actions']))\n",
    "    original_trajectory = np.array(original_trajectory_states)\n",
    "\n",
    "\n",
    "    logging.info(f\"正在连接到服务器 ws://{HOST}:{PORT}\")\n",
    "    client = _websocket_client_policy.WebsocketClientPolicy(HOST, PORT)\n",
    "\n",
    "    all_inferred_actions = []\n",
    "    \n",
    "    # 首次推理\n",
    "    # 使用第一个 object 的数据进行初始化\n",
    "    current_state = np.array(episode_data[0]['state'])\n",
    "    image_path = episode_data[0]['image_path']\n",
    "    \n",
    "    logging.info(\"开始循环推理...\")\n",
    "    for i in range(0, MAX_STEPS, REPLAN_STEPS):\n",
    "        logging.info(f\"正在执行推理步: {i+1}-{i+REPLAN_STEPS}\")\n",
    "        \n",
    "        # 构造输入 example\n",
    "        # image 固定不变, wrist_image 和 state 变化\n",
    "        wrist_image_path = episode_data[i]['wrist_image_path']\n",
    "        \n",
    "        element = {\n",
    "            \"observation/image\": imageio.imread(image_path),\n",
    "            \"observation/wrist_image\": imageio.imread(wrist_image_path),\n",
    "            \"observation/state\": current_state,\n",
    "            \"prompt\": PROMPT\n",
    "        }\n",
    "\n",
    "        # 调用 server 进行推理\n",
    "        action_chunk = client.infer(element)[\"actions\"]\n",
    "        all_inferred_actions.extend(action_chunk)\n",
    "\n",
    "        # 更新下一次推理的状态\n",
    "        # 使用返回的动作序列的最后一个点的6D位姿作为下一次的起始状态\n",
    "        current_state = np.array(action_chunk[-1][:6])\n",
    "\n",
    "    logging.info(\"推理完成。\")\n",
    "\n",
    "    # 构造推理轨迹\n",
    "    # 推理出的轨迹是初始状态加上所有推理出的动作\n",
    "    inferred_trajectory_states = [np.array(episode_data[0]['state'])]\n",
    "    inferred_trajectory_states.extend([np.array(act[:6]) for act in all_inferred_actions])\n",
    "    inferred_trajectory = np.array(inferred_trajectory_states)\n",
    "    \n",
    "    # 确保两条轨迹长度一致以便比较\n",
    "    min_len = min(len(original_trajectory), len(inferred_trajectory))\n",
    "    original_trajectory = original_trajectory[:min_len]\n",
    "    inferred_trajectory = inferred_trajectory[:min_len]\n",
    "\n",
    "    # 计算偏差并输出结果\n",
    "    pos_mae, rot_mae, pos_errors = calculate_trajectory_deviation(original_trajectory, inferred_trajectory)\n",
    "\n",
    "    print(\"\\n--- 轨迹偏差分析 ---\")\n",
    "    print(f\"平均绝对位置误差 (Positional MAE): {pos_mae:.4f}\")\n",
    "    print(f\"平均绝对姿态误差 (Rotational MAE): {rot_mae:.4f}\")\n",
    "    print(\"\\n每个点的具体位置误差:\")\n",
    "    for i, err in enumerate(pos_errors):\n",
    "        print(f\"  点 {i}: {err:.4f}\")\n",
    "    print(\"------------------------\\n\")\n",
    "\n",
    "    # 可视化轨迹\n",
    "    logging.info(\"正在生成轨迹对比图...\")\n",
    "    visualize_trajectories_3d(original_trajectory, inferred_trajectory)\n",
    "    visualize_trajectories_2d_topdown(original_trajectory, inferred_trajectory)    \n",
    "\n",
    "    # 从EPISODE_DATA_PATH动态生成输出JSON文件名\n",
    "    episode_match = re.search(r'episode_(\\d+)\\.parquet$', EPISODE_DATA_PATH)\n",
    "    if episode_match:\n",
    "        episode_num = episode_match.group(1)\n",
    "        output_filename = f\"inferred_trajectory_{episode_num}.json\"\n",
    "    else:\n",
    "        output_filename = \"inferred_trajectory.json\" # Fallback\n",
    "\n",
    "    output_path = f\"/data/vla/VLA_Diff/Openpi/test/infer/trajectory_video/{output_filename}\"\n",
    "    logging.info(f\"正在保存推理轨迹到 {output_path}...\")\n",
    "\n",
    "    # 准备用于JSON输出的数据列表\n",
    "    output_data = []\n",
    "    # 遍历原始的 episode 数据，以其长度为准\n",
    "    for i in range(len(episode_data)):\n",
    "        # 确保我们不会因为推理出的点数较少而出错\n",
    "        if i < len(inferred_trajectory):\n",
    "            # inferred_trajectory 的第一个点是初始状态，后续的点才是动作结果。\n",
    "            # 因此，第 i 个 object 对应的 action 是 inferred_trajectory 的第 i+1 个点。\n",
    "            # 我们需要检查 i+1 是否仍在 inferred_trajectory 的范围内。\n",
    "            if (i + 1) < len(inferred_trajectory):\n",
    "                action = inferred_trajectory[i+1].tolist()\n",
    "            else:\n",
    "                # 如果没有对应的推理动作（例如在最后一个点），则设为 None 或空列表\n",
    "                action = None\n",
    "        else:\n",
    "            action = None\n",
    "\n",
    "        output_data.append({\n",
    "            \"prompt\": PROMPT,\n",
    "            \"wrist_image_path\": episode_data[i]['wrist_image_path'],\n",
    "            \"state\": episode_data[i]['state'],\n",
    "            \"actions\": action\n",
    "        })\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "    \n",
    "    logging.info(f\"推理轨迹已保存到 {output_path}\")\n",
    "\n",
    "    # # 自动调用脚本生成视频\n",
    "    # logging.info(\"正在调用脚本生成轨迹视频...\")\n",
    "    # try:\n",
    "    #     generate_video_from_trajectory(output_path)\n",
    "    #     logging.info(\"视频生成完毕。\")\n",
    "    # except Exception as e:\n",
    "    #     logging.error(f\"生成视频时出错: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
